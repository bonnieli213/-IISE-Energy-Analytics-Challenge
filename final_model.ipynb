{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from tqdm import tqdm\n",
    "# make sure that you have xgboost installed:\n",
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# make sure that you have xgboost installed:\n",
    "# pip install xgboost\n",
    "\n",
    "def add_lag(X, y, lag):\n",
    "    '''\n",
    "    Args:\n",
    "    - X:    [ len, n_attr ]\n",
    "    - y:    [ len ]\n",
    "    Returns:\n",
    "    - X_lag [ len - lag, (n_attr + 1) * lag ]\n",
    "    - y_lag [ len - lag ]\n",
    "    '''\n",
    "    y_lag = y[lag:]                             # [ len - lag ]\n",
    "    X_lag = [ np.concatenate([X[i-lag:i], y[i-lag:i][:, None]], 1)  for i in range(lag, len(X), 1) ] # each [ lag, n_attr + 1 ]\n",
    "    X_lag = [ x.reshape(-1) for x in X_lag ]    # each [ lag * n_attr + 1 ]    \n",
    "    X_lag = np.stack(X_lag, 0)                  # [ len - lag, (n_attr + 1) * lag ]\n",
    "    return X_lag, y_lag\n",
    "\n",
    "def add_lag_X(X, lag):\n",
    "    '''\n",
    "    Args:\n",
    "    - X:    [ len, n_attr ]\n",
    "    Returns:\n",
    "    - X_lag [ len, n_attr * lag ]\n",
    "    '''\n",
    "    X_lag = [ X[i-lag:i]  for i in range(lag, len(X), 1) ] # each [ lag, n_attr + 1 ]\n",
    "    X_lag = [ x.reshape(-1) for x in X_lag ]    # each [ lag * n_attr + 1 ]    \n",
    "    X_lag = np.stack(X_lag, 0)                  # [ len - lag, (n_attr + 1) * lag ]\n",
    "    X_lag = np.concatenate([np.zeros([lag, X_lag.shape[1]]),X_lag],0)\n",
    "    return X_lag\n",
    "    \n",
    "class XGBoost_AR:\n",
    "    '''Autoregressive adaptation of XGBoost'''\n",
    "    def __init__(self, kwds, lag):\n",
    "        self.model   = XGBRegressor(**kwds)\n",
    "        self.lag = lag\n",
    "\n",
    "    def fit(self, Xtr, ytr):\n",
    "        '''\n",
    "        Args:\n",
    "        - Xtr:    [ len, n_attr ]\n",
    "        - ytr:    [ len ]\n",
    "        '''\n",
    "        Xtr_, ytr_ = add_lag(Xtr, ytr, self.lag)\n",
    "        self.model.fit(Xtr_, ytr_)\n",
    "\n",
    "    def predict(self, Xte):\n",
    "        '''\n",
    "        Args:\n",
    "        - Xte:  [ len_te, n_attr ]\n",
    "        Returns:\n",
    "        - yte:  [ len_te ]\n",
    "        '''\n",
    "        yte = np.ones(self.lag)\n",
    "        for i in tqdm(range(self.lag + 1, len(Xte), 1), desc = 'Predicting'):\n",
    "            Xte_, _ = add_lag(Xte[:i], yte[:i], self.lag)\n",
    "            yte = self.model.predict(Xte_)\n",
    "            yte = np.concatenate([np.ones(self.lag) * np.mean(yte), yte], 0)\n",
    "        return yte\n",
    "    \n",
    "class XGBoost_AR_Half:\n",
    "    '''A more computationally efficient version than its full version, but may be less powerful'''\n",
    "    def __init__(self, kwds, lag):\n",
    "        self.model   = XGBRegressor(**kwds)\n",
    "        self.lag = lag\n",
    "\n",
    "    def fit(self, Xtr, ytr):\n",
    "        '''\n",
    "        Args:\n",
    "        - Xtr:    [ len, n_attr ]\n",
    "        - ytr:    [ len ]\n",
    "        '''\n",
    "        Xtr_ = add_lag_X(Xtr, self.lag)\n",
    "        self.model.fit(Xtr_, ytr)\n",
    "\n",
    "    def predict(self, Xte):\n",
    "        '''\n",
    "        Args:\n",
    "        - Xte:  [ len_te, n_attr ]\n",
    "        Returns:\n",
    "        - yte:  [ len_te ]\n",
    "        '''\n",
    "        Xte_ = add_lag_X(Xte, self.lag)\n",
    "        yte = self.model.predict(Xte_)\n",
    "        return yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiresBoosting:\n",
    "\n",
    "    def __init__(self, df):\n",
    "        # df = pd.read_excel(training_path)\n",
    "        self.df = df\n",
    "        time_metadata = df.iloc[:, :4]\n",
    "        self.y = df.iloc[:, 4].values\n",
    "        self.X = df.iloc[:, 5:].values\n",
    "        # index to date\n",
    "        time_metadata['Date'] = time_metadata['Year'].astype('str') + '_' + time_metadata['Month'].astype('str') + '_' + time_metadata['Day'].astype('str')\n",
    "        self.P_date = pd.get_dummies(time_metadata['Date']).values\n",
    "        # index to fake month\n",
    "        time_metadata['Fake Month'] = time_metadata['Year'].astype('str') + '_' + time_metadata['Month'].astype('str')\n",
    "        self.P_fmonth = pd.get_dummies(time_metadata['Fake Month']).values\n",
    "        # index to month\n",
    "        self.P_month = pd.get_dummies(time_metadata['Month']).values    # [ num_data, num_months ]\n",
    "        # index to hour\n",
    "        self.P_hour  = pd.get_dummies(time_metadata['Hour']).values    # [ num_data, num_hours ]\n",
    "        kwds = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'max_depth': 10,\n",
    "        'learning_rate': 1e-1,\n",
    "        'n_estimators': 100\n",
    "        }\n",
    "\n",
    "        self.models = [ XGBoost_AR_Half(kwds, lag=11) for _ in range(3) ]\n",
    "        \n",
    "    def fit(self):\n",
    "        # Step 1: de-trend the data \n",
    "        self.avg_month  = self.df.groupby('Month').mean()['Load'].values    # [ 12 ]\n",
    "        self.avg_hour   = self.df.groupby('Hour').mean()['Load'].values     # [ 24 ]\n",
    "        self.y = self.y - self.avg_month @ self.P_month.T - self.avg_hour @ self.P_hour.T # [ num_data ]\n",
    "\n",
    "        # Step 2: fitting first level model\n",
    "        P_fmonth = self.P_fmonth / self.P_fmonth.sum(0)\n",
    "        X_fmonth = P_fmonth.T @ self.X  # [ num_fake_months, num_covs ]\n",
    "        y_fmonth = P_fmonth.T @ self.y  # [ num_fake_months ]\n",
    "        self.models[0].fit(X_fmonth, y_fmonth)   # TODO\n",
    "        y_fit_fmonth = self.models[0].predict(X_fmonth)\n",
    "\n",
    "        # Step 3: fitting second level model\n",
    "        P_date = self.P_date / self.P_date.sum(0) # [ num_data, num_dates ]\n",
    "        X_date = P_date.T @ self.X  # [ num_date, num_covs ]\n",
    "        y_date = P_date.T @ self.y - P_date.T @ self.P_fmonth @ y_fit_fmonth # [ num_date ]\n",
    "        self.models[1].fit(X_date, y_date)   # TODO\n",
    "        y_fit_date = self.models[1].predict(X_date)\n",
    "\n",
    "        # Step 3: fitting third level model\n",
    "        X = self.X\n",
    "        y = self.y - self.P_date @ y_fit_date - self.P_fmonth @ y_fit_fmonth\n",
    "        self.models[2].fit(X, y)    # TODO\n",
    "\n",
    "    def predict(self, df):\n",
    "        '''\n",
    "        df: the test dataframe\n",
    "        '''\n",
    "        time_metadata = df.iloc[:, :4]\n",
    "        X = df.iloc[:, 5:].values\n",
    "        # index to date\n",
    "        time_metadata['Date'] = time_metadata['Year'].astype('str') + '_' + time_metadata['Month'].astype('str') + '_' + time_metadata['Day'].astype('str')\n",
    "        P_date = pd.get_dummies(time_metadata['Date']).values\n",
    "        # index to fake month\n",
    "        time_metadata['Fake Month'] = time_metadata['Year'].astype('str') + '_' + time_metadata['Month'].astype('str')\n",
    "        P_fmonth = pd.get_dummies(time_metadata['Fake Month']).values\n",
    "        # index to month\n",
    "        P_month = pd.get_dummies(time_metadata['Month']).values    # [ num_data, num_months ]\n",
    "        # index to hour\n",
    "        P_hour  = pd.get_dummies(time_metadata['Hour']).values    # [ num_data, num_hours ]\n",
    "\n",
    "        # TODO: input X and get y\n",
    "        y =         self.models[2].predict(X)\n",
    "        P_date_ =    P_date / P_date.sum(0) # [ num_data, num_dates ]\n",
    "        X_date =    P_date_.T @ X  # [ num_date, num_covs ]\n",
    "        y_date =    self.models[1].predict(X_date)           \n",
    "        P_fmonth_ =  P_fmonth / P_fmonth.sum(0)\n",
    "        X_fmonth =  P_fmonth_.T @ X  # [ num_fake_months, num_covs ]\n",
    "        y_fmonth =  self.models[0].predict(X_fmonth)\n",
    "        output =    y + y_fmonth @ P_fmonth.T + y_date @ P_date.T + self.avg_month @ P_month.T + self.avg_hour @ P_hour.T\n",
    "        return output   # [ num_test_data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('data/training.xlsx')\n",
    "test = pd.read_excel(\"data/testing.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2019.99830945, 1954.11322053, 1919.79584707, ..., 2244.85536549,\n",
       "       2093.41008037, 1988.1158298 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = MultiresBoosting(train)\n",
    "final_model.fit()\n",
    "y_pred = final_model.predict(test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019.998309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1954.113221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1919.795847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1928.367666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990.887502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Load\n",
       "0  2019.998309\n",
       "1  1954.113221\n",
       "2  1919.795847\n",
       "3  1928.367666\n",
       "4  1990.887502"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Load':y_pred})\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel('Results_CMUGridElfs.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
